<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>README</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .content {
            margin: 0 auto;
            max-width: 800px;
        }
        .text-justify {
            text-align: justify;
        }
    </style>
</head>
<body class="container mt-5">
    
    <div class="content">
        <h1 class="text-center">Curvy: A Parametric Cross-section based Surface Reconstruction</h1>
        <img src="curvy_arch.png" class="img-fluid" alt="Project Image">
        <div class="text-center">
            <a href="https://github.com/graphics-research-group/curvy" class="btn btn-primary">GitHub</a>
        </div>
        <p class="text-justify">Cross-sections with the help of generative modeling. We present a simple learnable approach to generate a large number
        of points from a small number of input cross-sections over a large dataset. We use a compact parametric polyline
        representation using adaptive splitting to represent the cross-sections and perform learning using a Graph Neural
        Network to reconstruct the underlying shape in an adaptive manner reducing the dependence on the number of
        cross-sections provided.</p>
        
        Our method proposes a novel approach to generate a large number of points from a small number of input cross-sections over a large dataset. We use a compact parametric polyline representation using adaptive splitting to represent the cross-sections and perform learning using a Graph Neural Network to reconstruct the underlying shape in an adaptive manner reducing the dependence on the number of cross-sections provided.
       
        <div class="text-center">
            <figure>
                <img src="assets/parametirc_repr.png" class="img-fluid" alt="curve representation">
                <figcaption class="text-justify">
                    <p class="text-justify"></p>
                Network to learn the underlying shape. The network is trained on a large dataset of shapes and cross-sections and is
                able to generate a large number of points from a small number of input cross-sections. The network is able to generate a
                large number of points from a small number of input cross-sections and is able to generate a large number of points from
                a small number of input cross-sections. The network is able to generate a large number of points from a small number of
                input cross-sections which is then uses as the input for the GCN network.
                </p></figcaption>
                </p>
            </figcaption>
            <!-- <img src="assets/parametirc_repr.png" class="img-fluid" alt="curve representation"> -->
            
        </div>

        <figure>
            <img src="assets/samples_cr_inc.png" class="img-fluid" alt="GCN">
            <!-- <img src="assets/parametirc_repr.png" class="img-fluid" alt="curve representation"> -->
            <figcaption class="text-center">Graph based representation allows to input a variable number of cross-sections to the network.</figcaption>
        </figure>
        

        <!-- <p class="text-justify">This repository contains scripts for training the Curvy network.</p> -->

        <h2 class="text-justify">Installation</h2>
        <p class="text-justify">Instructions on how to install and set up the project.</p>
        <pre><code>
        # Clone the repository
        git clone https://github.com/graphics-research-group/curvy.git
        
        # Navigate to the project directory
        cd curvy
        </code></pre>

        <h2 class="text-justify">Usage</h2>
        <ol class="text-justify">
            <li><strong>Data Preprocessing</strong>:
                <p>To generate cross-section data download ShapeNetCore.v2 dataset provided <a href="https://shapenet.org/">here</a>, set the paths in lines 574 where <code>root</code> refers to the path where ShapeNet dataset is downloaded and <code>target</code> is the path where the generated data will be stored in <code>Data_Prep.py</code> and run</p>
                <pre><code>python Data_Prep.py</code></pre>
            </li>
            <li><strong>Train AE</strong>:
                <p>Download data from the original PointNet repository <a href="https://github.com/charlesq34/pointnet">here</a></p>
                <pre><code>python ae_paper.py --data_dir /path/to/preprocessed_data</code></pre>
            </li>
            <li><strong>Train GCN</strong>:
                <p>To train the GCN set the following paths -</p>
                <ul>
                    <li>line 962: path to shapenet dataset</li>
                    <li>line 963: path to the generate cross-section data</li>
                    <li>lines 1011-1012: the path for the autoencoder checkpoint (note: the same path would be used for loading both the encoder and decoder models)</li>
                </ul>
                <p>then run -</p>
                <pre><code>python gcn.py</code></pre>
            </li>
        </ol>
    </div>
</body>
</html>
